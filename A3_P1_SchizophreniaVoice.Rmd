---
title: "Assignment2_Part1_VoiceInSchizophrenia"
author: "Kiri Koppelgaard"
date: "October 12, 2018"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Assignment 2 - Part 1 - Assessing voice in schizophrenia

Schizophrenia has been associated with "inappropriate" voice, sometimes monotone, sometimes croaky. A few studies indicate that pitch might be an index of schizophrenia. However, an ongoing meta-analysis of the literature (which you will have a go at in the last assignment) indicates that pitch mean and standard deviation are only weak indicators of diagnosis. Can we do better with our new fancy complex skills?

The corpus you are asked to analyse is a set of voice recordings from people with schizophrenia (just after first diagnosis) and 1-1 matched controls (on gender, age, education). Each participant watched 10 videos of triangles moving across the screen and had to describe them (so you have circa 10 recordings per person). We have already extracted the pitch once every 10 milliseconds and you will have to use this data to assess differences in the voice.

Can you characterize voice in schizophrenia as acoustically different? Report the methods you used to answer this question and the results from the analyses. Add a couple of lines trying to interpret the results (make sense of the difference). E.g. People with schizophrenia tend to have high-pitched voice, and present bigger swings in their prosody than controls. Add a couple of lines describing limitations of the data/analyses if any is relevant.


N.B. There are looots of files to be dealt with. Maybe too many for your computer, depending on how you load the files. This is a challenge for you. Some (complementary) possible strategies:
- You can select a subset of files only (and you have to justify your choice).
- You can learn how to use the apply() or map() functions.
- You can coordinate with classmates.

Hint: There is some information in the filenames that you might need.
```{r, include=FALSE}
setwd("~/Cognitive Science/3. Semester/Experimental Methods 3/Portfolio-2/Pitch/")
library(pacman)
p_load(tidyverse, stringr, Metrics, caret, lme4, simr, lmerTest, stats, FinCal, PerformanceAnalytics, nonlinearTseries)

p1 <- read.table("Study1D0S101T1_f0.txt", sep="\t", header = TRUE)
p1.ts<-ts(p1)
#data <- lapply(dir(),read.table)

#lapply('Study1D0S101T*.txt', read.table, environment("~/Cognitive Science/3. Semester/Experimental Methods 3/Portfolio-2/Pitch/"))
```

1. In the course of this assignment you have to first select one datafile and figure out how to:

- Extract "standard" descriptors of pitch: Mean, standard deviation, range
```{r, include = FALSE}
mean(p1$f0)
sd(p1$f0)
range(p1$f0)
```

- Extract less "standard" descriptors of pitch you can think of (e.g. median, iqr, mean absoluted deviation, coefficient of variation)
```{r, include = FALSE}
quantile(p1$f0)
IQR(p1$f0)
MeanAbsoluteDeviation(p1$f0)
coefficient.variation(sd=sd(p1$f0), avg=mean(p1$f0))
```

- Extract "complex" descriptors: recurrence quantification analysis
```{r, include = FALSE}
rqa.analysis=rqa(time.series = p1.ts, embedding.dim=2, time.lag=1,
               radius=1.2,lmin=2,do.plot=FALSE,distanceToBorder=2)
plot(rqa.analysis)
```


2. Second you will have to turn the code into a function and loop through all the files (or even better use apply/sapply/lapply)
- Remember to extract the relevant information from the file names (Participant, Diagnosis, Trial, Study)

```{r, include = FALSE}
read_pitch <- function(filename) {
#read data  
  participant <- read.table(str_c("Pitch/",filename), header = TRUE)
#parse filename; study, diagnosis, subject, trial
  name = str_match(filename,"Study(\\d+)D([01])S(\\d+)T(\\d+)")
  clinical = as.data.frame(t(name[2:length(name)]))
  names(clinical) = c("study","diagnosis","subject","trial")
#extract descriptors
  mean <- mean(participant$f0)
  sd <- sd(participant$f0)
  min <- min(participant$f0)
  max <- max(participant$f0)
  range <- max-min
  median <- median(participant$f0)
  iqr <- IQR(participant$f0)
  mad <- mad(participant$f0)
  coefvar <- coefficient.variation(sd(participant$f0), mean(participant$f0))
  data <- data.frame(mean, sd, min, max, range, median, iqr, mad, coefvar)
#combine all this data
return(cbind(clinical,data))
}

# when you've created a function that works, you can
pitch_data = list.files("Pitch/") %>% map_df(read_pitch)

##Join with demographic data

# Load demo data
setwd("~/Cognitive Science/3. Semester/Experimental Methods 3/Portfolio-2/")
demodata <- read.table("DemoData.txt",header=TRUE)
colnames(pitch_data)[3] <- "Subject"

#mutate new colum with subject id AND diagnosis to distinguish between subjects with and without schizophrenia
pitch_data <- pitch_data %>%
  mutate(Sub_Diag = str_c(Subject, diagnosis, sep = ""))

#mutate new colum with renamed diagnosis from demo-data
demodata$Diagnosis <- ifelse(demodata$Diagnosis == "Control", 0, 1)

demodata <- demodata %>%
  mutate(Sub_Diag = str_c(Subject, Diagnosis, sep = ""))

#demodata_meta <- subset(demodata, select = -c (SANS, SAPS, Social, NegLang, PosLang, Lang, Triangles, Alogia, FlatAffect, Asociality))

demodata$Subject <- as.character(demodata$Subject)

#merging datafiles in order to obtain the meta-data: gender, age, etc.
all_pitch <- right_join(demodata, pitch_data, by = c("Sub_Diag", "Subject"))

#reordering for a good look
colnames(all_pitch)
all_pitch <- all_pitch%>%select(Sub_Diag, Subject, diagnosis, study, trial, Gender, Age, Education, mean, sd, min, max, range, median, iqr, mad, coefvar, SANS, SAPS, Social, NegLang, PosLang, Lang, Triangles, Alogia, FlatAffect, Asociality)

write.csv(all_pitch, file = "pitch_data.csv")

```


3. Make one model per acoustic feature and test whether you can observe significant difference due to Diagnosis. Tip: Which other fixed factors should you control for (that is, include in the model)? Which random ones?
- Bonus points: cross-validate the model and report the betas and standard errors from all rounds to get an idea of how robust the estimates are. 

```{r, include = FALSE, eval = FALSE}

model_mean <-lmer(mean ~ Diagnosis + Gender  + (1+trial|Subject.x) + (1+trial|Study), data = all_pitch, REML = FALSE)
summary(model_mean)

model_range <- lmer(range ~ Diagnosis + Gender  + (1+trial|Subject.x) + (1+trial|Study), data = all_pitch, REML = FALSE)
summary(model_range)

model_sd <-lmer(sd ~ Diagnosis + Gender  + (1+trial|Subject.x) + (1+trial|Study), data = all_pitch, REML = FALSE)
summary(model_sd)

model_median <-lmer(median ~ Diagnosis + Gender  + (1+trial|Subject.x) + (1+trial|Study), data = all_pitch, REML = FALSE)
summary(model_median)

model_iqr <-lmer(iqr ~ Diagnosis + Gender  + (1+trial|Subject.x) + (1+trial|Study), data = all_pitch, REML = FALSE)
summary(model_iqr)

model_mad <-lmer(mad ~ Diagnosis + Gender  + (1+trial|Subject.x) + (1+trial|Study), data = all_pitch, REML = FALSE)
summary(model_mad)

model_coefvar <-lmer(coefvar ~ Diagnosis + Gender  + (1+trial|Subject.x) + (1+trial|Study), data = all_pitch, REML = FALSE)
summary(model_coefvar)

model_min <-lmer(min ~ Diagnosis + Gender  + (1+trial|Subject.x) + (1+trial|Study), data = all_pitch, REML = FALSE)
summary(model_min)

model_max <-lmer(max ~ Diagnosis + Gender  + (1+trial|Subject.x) + (1+trial|Study), data = all_pitch, REML = FALSE)
summary(model_max)

mean_model1 <- lmer(mean ~ Diagnosis + Study + Gender + (1+trial|Subject.x),pitch_demo_fulljoin)
summary(mean_model1) #study = 0.18

mean_model2 <- lmer(mean ~ Diagnosis*Study + Gender + (1+trial|Subject.x),pitch_demo_fulljoin)
summary(mean_model2) #Diagnosis:Stdy = 0.00847 **, study = 0.02524 *

sd_model1 <- lmer(sd ~ Diagnosis + Study + Gender + (1+trial|Subject.x),pitch_demo_fulljoin)
summary(sd_model1) #Study = 0.838    
sd_model2 <- lmer(sd ~ Diagnosis*Study + Gender + (1+trial|Subject.x),pitch_demo_fulljoin)
summary(sd_model2) #Diagnosis:Stdy =  0.084 ., study = 0.383 

min_model1 <- lmer(min ~ Diagnosis + Study + Gender + (1+trial|Subject.x),pitch_demo_fulljoin)
summary(min_model1) #Study = 0.344 
min_model2 <- lmer(min ~ Diagnosis*Study + Gender + (1+trial|Subject.x),pitch_demo_fulljoin)
summary(min_model2) #Diagnosis:Stdy =  0.288, study = 0.193    

max_model1 <- lmer(max ~ Diagnosis + Study + Gender + (1+trial|Subject.x),pitch_demo_fulljoin)
summary(max_model1) #Study = 0.0136 * 
max_model2 <- lmer(max ~ Diagnosis*Study + Gender + (1+trial|Subject.x),pitch_demo_fulljoin)
summary(max_model2) #Diagnosis:Stdy = 0.000340 *, study = 0.000107 *

median_model1 <- lmer(median ~ Diagnosis + Study + Gender + (1+trial|Subject.x),pitch_demo_fulljoin)
summary(median_model1) #Study =  0.299  
median_model2 <- lmer(median ~ Diagnosis*Study + Gender + (1+trial|Subject.x),pitch_demo_fulljoin)
summary(median_model2) #Diagnosis:Stdy = 0.0314 *, study = 0.0858 . 

iqr_model1 <- lmer(iqr ~ Diagnosis + Study + Gender + (1+trial|Subject.x),pitch_demo_fulljoin)
summary(iqr_model1) #Study = 0.1283
iqr_model2 <- lmer(iqr ~ Diagnosis*Study + Gender + (1+trial|Subject.x),pitch_demo_fulljoin)
summary(iqr_model2) #Diagnosis:Stdy = 0.591, study = 0.416 

mad_model1 <- lmer(mad ~ Diagnosis + Study + Gender + (1+trial|Subject.x),pitch_demo_fulljoin)
summary(mad_model1) #Study = 0.564  
mad_model2 <- lmer(mad ~ Diagnosis*Study + Gender + (1+trial|Subject.x),pitch_demo_fulljoin)
summary(mad_model2) #Diagnosis:Stdy =  0.4718, study = 0.9412  

coefvar_model1 <- lmer(coefvar ~ Diagnosis + Study + Gender + (1+trial|Subject.x) ,pitch_demo_fulljoin)
summary(coefvar_model1) #Study = 0.447 
coefvar_model2 <- lmer(coefvar ~ Diagnosis*Study + Gender + (1+trial|Subject.x) ,pitch_demo_fulljoin)
summary(coefvar_model2) #Diagnosis:Stdy =  4.4e- 0.0803 ., study = 0.7852 

range_model1 <- lmer(range ~ Diagnosis + Study + Gender + (1+trial|Subject.x),pitch_demo_fulljoin)
summary(range_model1) #Study = 0.0394 * 
range_model2 <- lmer(range ~ Diagnosis*Study + Gender + (1+trial|Subject.x),pitch_demo_fulljoin)
summary(range_model2) #Diagnosis:Stdy =  0.00228 *, study = 0.00075 **
```


3a. Is study a significant predictor in these models? What should you infer from this? Does study interact with diagnosis? What should you infer from this?

4. Bonus Question: Compare effect size of diagnosis across the different measures. Which measure seems most sensitive?
- Tip: to compare across measures you need to put all of them on the same scale, that is, you need to "standardize" them (z-score)

5. Bonus question. In the Clinical Info file you have additional information about the participants. Which additional parameters (e.g. age, gender) should we control for? Report the effects.

6. Write a paragraph reporting methods and results

RESPONSE: 
Using lmertest to perform a mixed effects analysis of the relationship between the various acoustic features of the recordings of participants and diagnosis of schizophrenia. 

As fixed effects, we entered diagnosis (Control or schizophrenia) and gender into the model. 

As random effects, we had an intercept for subjects and study, as well as a by‐subject random slope for the effect of trial and a by‐study random slope for the effect of trial. 

Testing whether diagnosis is a significant predictor, p-values was obtained using the package LmerTest. We observe a significant impact of diagnosis, when using the model to predict the acoutic features: mean (p-value = 1.08e-15 *), minimum (p-value < 2e-16), max (p-value = 0.049), median (p-value = 3.05e-14), mean absolute deviation (p-value = 3.03e-09), coefficient variance (p-value = 4.4e-11) and range (p-value = 0.0259). Cases, where diagnosis was a non-significant predictor include standard deviation (p-value = 0.13) and interquartile range (p-value = 0.064)

Investigating the main effect and interaction effect between study and diagnosis, we use diagnosis, study and gender as fixed effect and a by‐subject random slope for the effect of trial as random effect.

We find that study is a significant predictor for the main in the models estimating the maximum (p-value = 0.014) and range (p-value = 0.04). This could indicate that there might be a systematic variance between studies, and they conduct the experiments systematically different. 

Furthermore, we find that study significantly interacts with diagnosis in the models estimating the mean (p-value = 0.008), standard deviation (p-value =  0.084), max (p-value = 0.0003), median (p-value = 0.03), mean absolute deviation (p-value = 0.4718), coefficient variance (p-value = 4.4e- 0.08) and range (p-value = 0.002). Thus, in a large number of cases their is  significant interaction between study and diagnosis. This could indicate that the method the patients are given diagnosis could be biased. 


[Next assignment: can we use these measures to build a tool that diagnoses people from voice only?]

## N.B. Remember to save the acoustic features of voice in a separate file, so to be able to load them next time


